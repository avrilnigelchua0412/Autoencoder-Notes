{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "243c7a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 03:17:38.084816: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-29 03:17:38.098374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753730258.113310   12043 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753730258.117492   12043 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753730258.128191   12043 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753730258.128216   12043 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753730258.128217   12043 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753730258.128219   12043 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-29 03:17:38.132459: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from autoencoder import Autoencoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09d1c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (66500, 28, 28, 1)\n",
      "Validation shape: (3500, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train_full, _), (x_test, _) = mnist.load_data()\n",
    "x_all = np.concatenate([x_train_full, x_test], axis=0).astype(\"float32\") / 255.0\n",
    "x_all = x_all[..., np.newaxis]\n",
    "\n",
    "x_train, x_val = train_test_split(x_all, test_size=0.05, random_state=42)\n",
    "\n",
    "print(\"Train shape:\", x_train.shape)\n",
    "print(\"Validation shape:\", x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52fe645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753d9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "latent_space_dim = 2\n",
    "decoder_out_filter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc55ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753730261.186428   12043 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder(input_shape, latent_space_dim, decoder_out_filter, conv_layers_config=[\n",
    "    {'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1)},\n",
    "    {'filters': 64, 'kernel_size': (3, 3), 'strides': (2, 2)},\n",
    "    {'filters': 64, 'kernel_size': (3, 3), 'strides': (2, 2)},\n",
    "    {'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1)}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7874439",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "890fc042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753730265.433865   12125 service.cc:152] XLA service 0x71ef04019200 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753730265.433905   12125 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-07-29 03:17:45.510836: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1753730265.947381   12125 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  19/2079\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.2047 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753730270.423051   12125 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - loss: 0.0570 - val_loss: 0.0442\n",
      "Epoch 2/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0434 - val_loss: 0.0421\n",
      "Epoch 3/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0414 - val_loss: 0.0403\n",
      "Epoch 4/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0401 - val_loss: 0.0398\n",
      "Epoch 5/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0394 - val_loss: 0.0393\n",
      "Epoch 6/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0389 - val_loss: 0.0392\n",
      "Epoch 7/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0383 - val_loss: 0.0385\n",
      "Epoch 8/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0379 - val_loss: 0.0383\n",
      "Epoch 9/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0377 - val_loss: 0.0380\n",
      "Epoch 10/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0375 - val_loss: 0.0381\n",
      "Epoch 11/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0372 - val_loss: 0.0377\n",
      "Epoch 12/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0370 - val_loss: 0.0376\n",
      "Epoch 13/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0369 - val_loss: 0.0374\n",
      "Epoch 14/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0367 - val_loss: 0.0374\n",
      "Epoch 15/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0366 - val_loss: 0.0373\n",
      "Epoch 16/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0365 - val_loss: 0.0372\n",
      "Epoch 17/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0364 - val_loss: 0.0373\n",
      "Epoch 18/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0362 - val_loss: 0.0371\n",
      "Epoch 19/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0360 - val_loss: 0.0371\n",
      "Epoch 20/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0360 - val_loss: 0.0371\n",
      "Epoch 21/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0359 - val_loss: 0.0370\n",
      "Epoch 22/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0359 - val_loss: 0.0368\n",
      "Epoch 23/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0357 - val_loss: 0.0369\n",
      "Epoch 24/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0357 - val_loss: 0.0368\n",
      "Epoch 25/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0368\n",
      "Epoch 26/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0354 - val_loss: 0.0367\n",
      "Epoch 27/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0353 - val_loss: 0.0370\n",
      "Epoch 28/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.0368\n",
      "Epoch 29/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0352 - val_loss: 0.0368\n",
      "Epoch 30/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.0366\n",
      "Epoch 31/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0352 - val_loss: 0.0365\n",
      "Epoch 32/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0350 - val_loss: 0.0364\n",
      "Epoch 33/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0351 - val_loss: 0.0364\n",
      "Epoch 34/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0350 - val_loss: 0.0366\n",
      "Epoch 35/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0349 - val_loss: 0.0365\n",
      "Epoch 36/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0350 - val_loss: 0.0364\n",
      "Epoch 37/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0348 - val_loss: 0.0365\n",
      "Epoch 38/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0347 - val_loss: 0.0364\n",
      "Epoch 39/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0347 - val_loss: 0.0364\n",
      "Epoch 40/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0346 - val_loss: 0.0363\n",
      "Epoch 41/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0346 - val_loss: 0.0362\n",
      "Epoch 42/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - loss: 0.0346 - val_loss: 0.0366\n",
      "Epoch 43/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0345 - val_loss: 0.0363\n",
      "Epoch 44/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0345 - val_loss: 0.0363\n",
      "Epoch 45/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0345 - val_loss: 0.0364\n",
      "Epoch 46/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0345 - val_loss: 0.0365\n",
      "Epoch 47/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0344 - val_loss: 0.0365\n",
      "Epoch 48/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0345 - val_loss: 0.0364\n",
      "Epoch 49/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.0343 - val_loss: 0.0363\n",
      "Epoch 50/50\n",
      "\u001b[1m2079/2079\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0343 - val_loss: 0.0364\n"
     ]
    }
   ],
   "source": [
    "autoencoder.train(train_config = {\n",
    "    'x_train': x_train,\n",
    "    'y_train': x_train, # Autoencoders typically use the same data for input and output\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': EPOCHS,\n",
    "    'validation_data': (x_val, x_val), # Validation data for monitoring\n",
    "    'shuffle': True\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
